LogisticRegression

머신러닝은 크게 지도학습과 비지도학습 그리고 강화학습으로 구분된다. 그중에서 지도학습의 기법인 로지스틱 회귀(LogisticRegression)에 대해 알아보고자 한다. 지도학습은 크게 분류(Classification)와 회귀(Regression)로 구분짓는데 로지스틱 회귀는 이름에 회귀(Regression)을 포함하고 있지만 대부분 분류를 목적으로 활용된다. 어떤 이유로 이름에 회귀를 포함하고 있지만 분류를 목적으로 사용하고 있는지 알아보고 로지스틱 회귀분석이란 어떤 것인지 정리를 통해 구체적으로 알아보겠다.

우선, 로지스틱 회귀를 알아보기 전에 회귀(Regression)란 무엇인지 구체적인 개념을 잡고 가보자. 회귀의 사전적 의미는 '한 바퀴 돌아서 본디의 자리나 상태로 돌아오는 것'이라고 한다. 분석에서 회귀는 평균으로 돌아가는 것을 뜻하며, 예를 들어 부모와 자녀의 키는 선형적인 관계가 있어 부모의 키가 크면 자녀의 키도 크겠지만 부모의 키가 아무리 커도 결국 자녀의 키는 자녀 세대의 평균으로 돌아가고 있는 것을 회귀한다고 표현한다.

선형 회귀 차트
선형 회귀 그래프

로지스틱 회귀는 선형 회귀의 목표와 동일하게 종속 변수와 독립 변수의 관계를 하나의 모델로 정의하고 예측에 활용하는 것이다. 이렇듯 독립 변수의 선형 결합으로 종속 변수를 설명하고 있기에 선형 회귀 분석과 유사하지만 로지스틱 회귀는 종속 변수가 연속형이 아닌 범주형이라는 점에서 분류 기법으로 활용된다. 즉, 독립 변수의 선형적 특징을 활용한다는 점이 이름에 회귀를 포함하고 있다고 보았고, 종속 변수가 범주형이기에 분류 기법으로 활용한다고 보여진다.

학습시간 합격여부 그래프


위의 그래프는 선형 회귀 분석을 통한 분류는 문제가 있음을 알수있다. 첫번째 그래프를 보면 22시간 이상 공부한 사람은 시험에 통과하였고 22시간 보다 적게 공부한 사람은 탈락하였다. 이 결과를 바탕으로 선형적인 모델을 만들면 경계선을 기준으로 22시간일때의 합격률은 0.6~0.7 정도가 나온다. 만약 여기서 새로운 데이터로 많은 시간을 공부해서 합격한 사람이 추가된다고 가정해보자. 결과값인  종속 변수가 최대값이 1이기 때문에 이때 만들어진 모델은 그 전 모델보다 기울기가 감소하게된다. 이때 문제가 생기는데 기울기가 감소하여 합격의 기준이 높아짐으로 그전에 합격이라고 예측했던 값들이 불합격으로 판단하게 되는 경우가 발생하게된다. 
























































로지스틱 회귀의 목적은 일반적인 회귀 분석의 목표와 동일하게 종속 변수와 독립 변수간의 관계를 구체적인 함수로 나타내어 향후 예측 모델에 사용하는 것이다. 이는 독립 변수의 선형 결합으로 종속 변수를 설명한다는 관점에서는 선형 회귀 분석과 유사하다. 하지만 로지스틱 회귀는 선형 회귀 분석과는 다르게 종속 변수가 범주형 데이터를 대상으로 하며 입력 데이터가 주어졌을 때 해당 데이터의 결과가 특정 분류로 나뉘기 때문에 일종의 분류 (classification) 기법으로도 볼 수 있다.


로지스틱 회귀는 일반적인 선형 모델(generalized linear model)의 특수한 경우로 볼 수 있으므로 선형 회귀와 유사하다. 하지만, 로지스틱 회귀의 모델은 종속 변수와 독립 변수 사이의 관계에 있어서 선형 모델과 차이점을 지니고 있다. 첫 번째 차이점은 이항형인 데이터에 적용하였을 때 종속 변수 y의 결과가 범위[0,1]로 제한된다는 것이고 두 번째 차이점은 종속 변수가 이진적이기 때문에 조건부 확률(P(y│x))의 분포가 정규분포 대신 이항 분포를 따른다는 점이다.

따라서, 대상이 되는 데이터의 종속 변수 y의 결과는 0과 1, 두 개의 경우만 존재하는 데 반해, 단순 선형 회귀를 적용하면 범위[0,1]를 벗어나는 결과가 나오기 때문에 오히려 예측의 정확도만 떨어뜨리게 된다.

이를 해결하기 위해 로지스틱 회귀는 연속이고 증가함수이며 [0,1]에서 값을 갖는 연결 함수 g(x)를 제안하였다. 연결함수의 형태는 다양하게 존재하는데 그 중 대표적인 두 개는 아래와 같다.
